{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7108648,"sourceType":"datasetVersion","datasetId":4098494}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2023-12-06T01:13:44.892212Z","iopub.execute_input":"2023-12-06T01:13:44.893021Z","iopub.status.idle":"2023-12-06T01:13:56.876045Z","shell.execute_reply.started":"2023-12-06T01:13:44.892986Z","shell.execute_reply":"2023-12-06T01:13:56.874998Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: split-folders in /opt/conda/lib/python3.10/site-packages (0.5.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.transforms import transforms\nimport os\nfrom PIL import Image\nimport torch\nimport ssl\nimport torchvision\nimport torchvision.models as models\nimport torch.optim as optim\nimport torch.nn as nn\nfrom tqdm import tqdm\nimport splitfolders\nimport csv\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport numpy as np\nimport warnings\n\n#warnings.filterwarnings('ignore')\n\n\ndef calculate_accuracy(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim=True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() / y.shape[0]\n    return acc\n\nssl._create_default_https_context = ssl._create_unverified_context\n\nif __name__ == '__main__':\n    # Define the device to be used for training\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Set up the transform to resize and normalize the images\n    transform = transforms.Compose([\n        transforms.Resize(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n            std=[0.5, 0.5, 0.5]),\n    ])\n\n    # Update input folder and output folder paths\n    input_folder = r\"/kaggle/input/images-highpassfilter-small-zip/IMAGES_HighPassFilter_Small\"\n    output_folder = r\"/kaggle/output/Images\"\n\n    ### Uncomment only for first time. once data is splitted into train and validation, comment it out\n    #splitfolders.ratio(input_folder, output_folder, seed=42, ratio=(0.8, 0.2), group_prefix=None)\n\n    # Create datasets for the training and testing sets\n    train_dataset = torchvision.datasets.ImageFolder(output_folder + '/train', transform=transform)\n    val_dataset = torchvision.datasets.ImageFolder(output_folder + '/val', transform=transform)\n    train_size = len(train_dataset)\n    val_size = len(val_dataset)\n\n    # Create the data loaders for training and validation\n    train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True,num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=5, shuffle=True,num_workers=4)\n    list_of_classes = os.listdir(r\"/kaggle/output/Images/train\")\n    print(list_of_classes)\n    classes = list(train_dataset.class_to_idx.keys())\n    classes.sort()\n\n\n    # Define the VGG model\n    model = torchvision.models.vgg16(pretrained=True)\n    num_features = model.classifier[0].in_features\n    model.classifier = nn.Sequential(\n        nn.Linear(num_features, 4096),\n        nn.ReLU(inplace=True),\n        nn.Dropout(0.5),\n        nn.Linear(4096, 4096),\n        nn.ReLU(inplace=True),\n        nn.Dropout(0.5),\n        nn.Linear(4096, len(list_of_classes))\n    )\n\n    ## uncomment for CPU\n    model = model.to(device)\n\n    # Define the loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    START_LR = 0.0001\n    optimizer = optim.Adam(model.parameters(), lr=START_LR)\n    model = model.to(device)\n    criterion = criterion.to(device)\n\n    ### uncomment for GPU\n    model.cuda()\n        # Train the model\n    for epoch in range(10):\n        ### uncomment for GPU\n        torch.cuda.empty_cache()\n        print('Epoch {}/{}'.format(epoch + 1, 10))\n        print('-' * 10)\n\n        running_loss = 0\n        running_corrects = 0\n\n        model.train()\n        predictions = []\n        true_labels = []\n        for inputs, labels in tqdm(train_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.extend(labels.cpu().numpy())\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            predictions.extend(preds.cpu().numpy())\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss / train_size\n        epoch_acc = running_corrects.double() / train_size\n        report_dict = classification_report(true_labels, predictions, target_names=list_of_classes,output_dict=True)\n        report_pd = pd.DataFrame(report_dict)\n        report_pd.to_csv('training-classification-epoch' + str(epoch + 1) + '.csv')\n        cnf_matrix = confusion_matrix(true_labels, predictions)\n        df_cm = pd.DataFrame(cnf_matrix / np.sum(cnf_matrix, axis=1)[:, None], index = [i for i in classes],\n                        columns = [i for i in classes])\n        df_cm.to_csv('confusion-matrix-train-epoch' + str(epoch + 1) + '.csv')\n        #acc = matrix.diagonal()/matrix.sum(axis=1)\n        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n        TP = np.diag(cnf_matrix)\n        TN = cnf_matrix.sum() - (FP + FN + TP)\n        FP = FP.astype(float)\n        FN = FN.astype(float)\n        TP = TP.astype(float)\n        TN = TN.astype(float)\n        ACC = (TP+TN)/(TP+FP+FN+TN)\n        TPR = TP/(TP+FN)\n        PPV = TP/(TP+FP)\n        print(\"accuracy for all classes in train phase\", ACC)\n        print(\"recall for all classes in train phase\", TPR)\n        print(\"precision for all classes in train phase\", PPV)\n        \n        pd.DataFrame(ACC, columns=['Accuracy']).to_csv('accuracy-train-epoch' + str(epoch + 1) + '.csv')\n        print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n        \n        # Delete data to clear GPU memory\n        del outputs\n        del preds\n        del labels\n        del inputs\n        torch.cuda.empty_cache()\n        \n        # Validation phase\n        running_loss = 0\n        running_corrects = 0\n        model.eval()  # set the model to evaluation mode\n        predictions = []\n        true_labels = []\n        for inputs, labels in tqdm(val_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.extend(labels.cpu().numpy())\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            predictions.extend(preds.cpu().numpy())\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss / val_size\n        epoch_acc = running_corrects.double() / val_size\n       \n        #classification_report(true_labels, predictions, target_names=list_of_classes,output_dict=True)\n        report_dict = classification_report(true_labels, predictions, target_names=list_of_classes,output_dict=True)\n        report_pd = pd.DataFrame(report_dict)\n        report_pd.to_csv('val-classification-epoch' + str(epoch + 1) + '.csv')\n        #matrix = confusion_matrix(true_labels, predictions)\n        cnf_matrix = confusion_matrix(true_labels, predictions)\n        df_cm = pd.DataFrame(cnf_matrix / np.sum(cnf_matrix, axis=1)[:, None], index = [i for i in classes],\n                        columns = [i for i in classes])\n        df_cm.to_csv('confusion-matrix-val-epoch' + str(epoch + 1) + '.csv')\n        #acc = matrix.diagonal()/matrix.sum(axis=1)\n        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n        TP = np.diag(cnf_matrix)\n        TN = cnf_matrix.sum() - (FP + FN + TP)\n        FP = FP.astype(float)\n        FN = FN.astype(float)\n        TP = TP.astype(float)\n        TN = TN.astype(float)\n        ACC = (TP+TN)/(TP+FP+FN+TN)\n        TPR = TP/(TP+FN)\n        PPV = TP/(TP+FP)\n        pd.DataFrame(ACC, columns=['Accuracy']).to_csv('accuracy-val-epoch' + str(epoch + 1) + '.csv')\n        print(\"accuracy for all classes in validation phase\", ACC)\n        print(\"recall for all classes in validation phase\", TPR)\n        print(\"precision for all classes in validation phase\", PPV)\n        print('Val Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n        \n        # Delete data to clear GPU memory\n        del outputs\n        del preds\n        del labels\n        del inputs\n        torch.cuda.empty_cache()\n                \n        \n\n    # Save the model\n    torch.save(model, 'vgg16_model.pth')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-06T02:36:32.820786Z","iopub.execute_input":"2023-12-06T02:36:32.821155Z","iopub.status.idle":"2023-12-06T03:00:02.967856Z","shell.execute_reply.started":"2023-12-06T02:36:32.821122Z","shell.execute_reply":"2023-12-06T03:00:02.966657Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"['fotdro5', 'fislov1', 'hadibi1', 'pabspa1', 'gobbun1', 'whbwea1', 'gbesta1', 'yebere1', 'categr', 'afrthr1', 'grwpyt1', 'chucis1', 'grbcam1', 'mabeat1', 'scrcha1', 'bkctch1', 'vimwea1', 'mouwag1', 'wtbeat1', 'whbwhe3', 'hunsun2', 'whbtit5', 'kvbsun1', 'varsun2', 'squher1', 'blhgon1', 'afrgrp1', 'crheag1', 'blnwea1', 'stusta1']\nEpoch 1/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:08<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99034443 0.92765528 0.91194697 0.98472402 0.99135322 0.75616083\n 0.98731806 0.97982418 0.99409137 0.67026949 0.96253062 0.92160254\n 0.90286785 0.9877504  0.92318778 0.99596484 0.99567661 0.98962387\n 0.97261853 0.99639718 0.97247442 0.98991209 0.99711774 0.91670269\n 0.98731806 0.98962387 0.99250612 0.97809483 0.98717394 0.9711774 ]\nrecall for all classes in train phase [0.         0.38961039 0.1838843  0.         0.         0.65714286\n 0.         0.00714286 0.         0.59786822 0.00793651 0.29245283\n 0.06640625 0.         0.37575758 0.         0.         0.\n 0.14457831 0.         0.04848485 0.         0.         0.43428571\n 0.         0.         0.         0.11643836 0.         0.06586826]\nprecision for all classes in train phase [       nan 0.45       0.29180328        nan        nan 0.322\n        nan 0.5               nan 0.24779116 0.16666667 0.33695652\n 0.14782609 0.         0.45365854 0.                nan        nan\n 0.33333333        nan 0.19047619        nan        nan 0.44793713\n        nan        nan        nan 0.425             nan 0.2       ]\nTrain Loss: 2.4363 Acc: 0.3120\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99028571 0.97028571 0.89371429 0.98457143 0.99085714 0.91714286\n 0.98742857 0.98       0.99371429 0.86       0.96342857 0.89657143\n 0.87714286 0.988      0.88571429 0.996      0.99542857 0.98971429\n 0.96228571 0.996      0.97771429 0.98971429 0.99714286 0.94228571\n 0.98742857 0.98914286 0.992      0.98685714 0.98057143 0.976     ]\nrecall for all classes in validation phase [0.         0.69827586 0.67768595 0.         0.         0.47560976\n 0.         0.02777778 0.         0.62015504 0.         0.70093458\n 0.25       0.         0.91129032 0.         0.         0.\n 0.80952381 0.         0.0952381  0.         0.         0.66666667\n 0.         0.         0.         0.59459459 0.47826087 0.        ]\nprecision for all classes in validation phase [       nan 0.82653061 0.3580786         nan        nan 0.87969925\n        nan 1.                nan 0.52117264        nan 0.33482143\n 0.21192053        nan 0.37417219        nan        nan        nan\n 0.36956522        nan 0.8               nan        nan 0.60689655\n        nan        nan        nan 0.73333333 0.33333333        nan]\nVal Loss: 1.9560 Acc: 0.4686\nEpoch 2/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:09<00:00, 10.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.98947975 0.96469232 0.94321948 0.98400346 0.99135322 0.92088197\n 0.98659749 0.98342701 0.99394725 0.84709612 0.95964836 0.95244272\n 0.91108229 0.98746217 0.96051304 0.99625306 0.99567661 0.98962387\n 0.98630927 0.99639718 0.974492   0.98947975 0.99711774 0.94350771\n 0.98630927 0.98919153 0.99250612 0.98530048 0.98688572 0.97578902]\nrecall for all classes in train phase [0.01492537 0.70995671 0.55165289 0.00943396 0.         0.83061224\n 0.14772727 0.52142857 0.         0.78100775 0.17460317 0.60849057\n 0.51171875 0.19277108 0.76767677 0.         0.         0.09722222\n 0.69277108 0.         0.35757576 0.05714286 0.         0.77142857\n 0.         0.         0.         0.6369863  0.19101124 0.38323353]\nprecision for all classes in train phase [0.125      0.74715262 0.60135135 0.14285714        nan 0.68003342\n 0.41935484 0.60330579 0.         0.49116392 0.37931034 0.61137441\n 0.41653418 0.44444444 0.70500928        nan        nan 0.5\n 0.72327044        nan 0.45384615 0.36363636        nan 0.59822747\n 0.         0.                nan 0.65492958 0.47222222 0.49612403]\nTrain Loss: 1.5241 Acc: 0.5803\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99028571 0.96228571 0.94857143 0.98057143 0.99085714 0.94971429\n 0.98914286 0.98       0.99085714 0.888      0.95828571 0.96914286\n 0.93371429 0.992      0.96342857 0.996      0.99542857 0.99085714\n 0.99428571 0.996      0.96228571 0.98971429 0.99714286 0.96171429\n 0.98628571 0.98914286 0.992      0.98971429 0.98628571 0.96742857]\nrecall for all classes in validation phase [0.         0.81034483 0.30578512 0.2962963  0.         0.79674797\n 0.22727273 0.69444444 0.         0.86821705 0.46875    0.70093458\n 0.6953125  0.38095238 0.69354839 0.         0.         0.16666667\n 0.76190476 0.         0.66666667 0.11111111 0.         0.84090909\n 0.09090909 0.         0.         0.56756757 0.47826087 0.80952381]\nprecision for all classes in validation phase [       nan 0.68115942 0.86046512 0.34782609        nan 0.83760684\n 0.71428571 0.51020408 0.         0.58031088 0.43478261 0.77319588\n 0.53614458 0.88888889 0.76785714        nan        nan 0.75\n 1.                nan 0.35       0.5               nan 0.70700637\n 0.33333333        nan        nan 0.91304348 0.47826087 0.40963855]\nVal Loss: 1.3187 Acc: 0.6406\nEpoch 3/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:09<00:00, 10.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.98947975 0.97607724 0.95258683 0.98616515 0.99120911 0.94350771\n 0.98832685 0.99063266 0.99380314 0.90257962 0.96454821 0.9678628\n 0.95330739 0.99077677 0.97045684 0.99596484 0.9955325  0.99149733\n 0.99308258 0.99625306 0.98011241 0.98861507 0.99711774 0.95878369\n 0.98702983 0.98861507 0.9922179  0.9877504  0.98947975 0.98299467]\nrecall for all classes in train phase [0.13432836 0.75974026 0.61983471 0.35849057 0.         0.87755102\n 0.42045455 0.77142857 0.19512195 0.83236434 0.44444444 0.72877358\n 0.73046875 0.34939759 0.78989899 0.         0.13333333 0.52777778\n 0.86746988 0.         0.56363636 0.24285714 0.         0.83619048\n 0.25       0.01388889 0.         0.73287671 0.58426966 0.64670659]\nprecision for all classes in train phase [0.375      0.86453202 0.6741573  0.57575758 0.         0.75971731\n 0.55223881 0.76595745 0.44444444 0.63069016 0.51376147 0.74100719\n 0.66785714 0.74358974 0.79471545 0.         0.44444444 0.6031746\n 0.84705882 0.         0.58490566 0.39534884        nan 0.68701095\n 0.47826087 0.11111111 0.         0.69934641 0.59090909 0.64670659]\nTrain Loss: 1.0948 Acc: 0.6932\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.98971429 0.97771429 0.96114286 0.98971429 0.98971429 0.94514286\n 0.99085714 0.99085714 0.99314286 0.93885714 0.976      0.98228571\n 0.94285714 0.99028571 0.96971429 0.996      0.99542857 0.99657143\n 0.99314286 0.99542857 0.98971429 0.98171429 0.99714286 0.96171429\n 0.988      0.98628571 0.99314286 0.99257143 0.98857143 0.98742857]\nrecall for all classes in validation phase [0.11764706 0.79310345 0.66115702 0.48148148 0.         0.87804878\n 0.36363636 0.75       0.         0.81782946 0.421875   0.78504673\n 0.9140625  0.42857143 0.84677419 0.         0.         0.83333333\n 0.9047619  0.14285714 0.73809524 0.55555556 0.         0.87121212\n 0.27272727 0.26315789 0.21428571 0.78378378 0.73913043 0.61904762]\nprecision for all classes in validation phase [0.4        0.85981308 0.74766355 0.76470588 0.         0.76595745\n 0.8        0.79411765 0.         0.77859779 0.84375    0.91304348\n 0.56796117 0.64285714 0.75539568        nan        nan 0.83333333\n 0.82608696 0.33333333 0.81578947 0.29411765        nan 0.6969697\n 0.54545455 0.33333333 0.75       0.85294118 0.5483871  0.8125    ]\nVal Loss: 1.0134 Acc: 0.7354\nEpoch 4/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:09<00:00, 10.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.98875919 0.97881539 0.9633953  0.99020032 0.99106499 0.96094538\n 0.99020032 0.99437959 0.99466782 0.93601383 0.97535668 0.97723015\n 0.97405966 0.99063266 0.97953596 0.99610895 0.99610895 0.99279435\n 0.99524427 0.99582072 0.98875919 0.99020032 0.99711774 0.96843926\n 0.98803862 0.98803862 0.99265024 0.99236201 0.98991209 0.98515636]\nrecall for all classes in train phase [0.37313433 0.82683983 0.72727273 0.60377358 0.15       0.91530612\n 0.5        0.84285714 0.29268293 0.87403101 0.59126984 0.7995283\n 0.859375   0.39759036 0.84040404 0.         0.4        0.63888889\n 0.88554217 0.24       0.73333333 0.37142857 0.         0.86857143\n 0.39772727 0.11111111 0.11538462 0.84931507 0.6741573  0.7245509 ]\nprecision for all classes in train phase [0.40983607 0.85077951 0.74261603 0.71111111 0.45       0.82672811\n 0.64705882 0.87407407 0.6        0.74177632 0.68663594 0.82281553\n 0.80291971 0.6875     0.86847599 0.         0.57142857 0.65714286\n 0.91304348 0.375      0.78064516 0.52              nan 0.75247525\n 0.53846154 0.2962963  0.54545455 0.8        0.59405941 0.67977528]\nTrain Loss: 0.8172 Acc: 0.7710\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 29.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99257143 0.98285714 0.968      0.98628571 0.98857143 0.972\n 0.98857143 0.99085714 0.99314286 0.916      0.97257143 0.97771429\n 0.97257143 0.99085714 0.984      0.99828571 0.99542857 0.99485714\n 0.996      0.996      0.99085714 0.99085714 0.99714286 0.96971429\n 0.98571429 0.98971429 0.99028571 0.99542857 0.99142857 0.99028571]\nrecall for all classes in validation phase [0.41176471 0.85344828 0.71900826 0.7037037  0.4375     0.91869919\n 0.54545455 0.72222222 0.         0.94186047 0.53125    0.90654206\n 0.7890625  0.42857143 0.83870968 0.57142857 0.         0.72222222\n 0.88095238 0.         0.88095238 0.33333333 0.         0.77272727\n 0.22727273 0.15789474 0.35714286 0.78378378 0.65217391 0.66666667]\nprecision for all classes in validation phase [0.7        0.88392857 0.79816514 0.54285714 0.38888889 0.88627451\n 0.54545455 0.8125     0.         0.648      0.65384615 0.76984127\n 0.82786885 0.69230769 0.92857143 1.                nan 0.76470588\n 0.94871795        nan 0.77083333 0.6               nan 0.816\n 0.38461538 0.6        0.38461538 1.         0.68181818 0.90322581]\nVal Loss: 0.8816 Acc: 0.7743\nEpoch 5/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:09<00:00, 10.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99308258 0.98645338 0.97031273 0.99409137 0.99164145 0.97189797\n 0.99293846 0.99682951 0.99437959 0.95604554 0.97852717 0.98429168\n 0.98068886 0.99120911 0.98011241 0.99610895 0.99639718 0.99582072\n 0.99682951 0.99697363 0.99034443 0.99250612 0.99740597 0.97492434\n 0.98976798 0.98962387 0.99308258 0.99538838 0.99466782 0.99120911]\nrecall for all classes in train phase [0.58208955 0.88961039 0.7768595  0.75471698 0.36666667 0.92755102\n 0.64772727 0.92142857 0.3902439  0.90213178 0.69047619 0.86320755\n 0.88671875 0.51807229 0.85454545 0.15384615 0.4        0.81944444\n 0.93975904 0.44       0.77575758 0.51428571 0.25       0.87809524\n 0.54545455 0.33333333 0.48076923 0.90410959 0.79775281 0.80838323]\nprecision for all classes in train phase [0.66101695 0.90528634 0.79324895 0.84210526 0.52380952 0.87996128\n 0.76       0.92142857 0.53333333 0.82026432 0.71020408 0.87769784\n 0.85660377 0.671875   0.86503067 0.44444444 0.63157895 0.78666667\n 0.92857143 0.61111111 0.81012658 0.66666667 0.625      0.80735552\n 0.60759494 0.5        0.54347826 0.88       0.78888889 0.82317073]\nTrain Loss: 0.6288 Acc: 0.8268\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99142857 0.98857143 0.96914286 0.99142857 0.98685714 0.95828571\n 0.98514286 0.99257143 0.99428571 0.94285714 0.97485714 0.98114286\n 0.97885714 0.99371429 0.96914286 0.99828571 0.99542857 0.996\n 0.996      0.99714286 0.988      0.99314286 0.99828571 0.97371429\n 0.98514286 0.992      0.99428571 0.99314286 0.99485714 0.99028571]\nrecall for all classes in validation phase [0.64705882 0.87068966 0.70247934 0.62962963 0.375      0.93495935\n 0.63636364 0.83333333 0.09090909 0.91085271 0.609375   0.85981308\n 0.7734375  0.71428571 0.90322581 0.85714286 0.5        0.77777778\n 0.85714286 0.71428571 0.5952381  0.5        0.4        0.81818182\n 0.18181818 0.47368421 0.28571429 0.81081081 0.60869565 0.69047619]\nprecision for all classes in validation phase [0.55       0.95283019 0.82524272 0.77272727 0.31578947 0.80139373\n 0.4375     0.81081081 1.         0.75320513 0.67241379 0.83636364\n 0.92523364 0.75       0.72727273 0.75       0.5        0.82352941\n 0.97297297 0.625      0.86206897 0.75       1.         0.83076923\n 0.33333333 0.69230769 1.         0.85714286 1.         0.87878788]\nVal Loss: 0.8238 Acc: 0.7920\nEpoch 6/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:09<00:00, 10.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99365903 0.9889033  0.97636547 0.99625306 0.9922179  0.97723015\n 0.99265024 0.99697363 0.99567661 0.96944805 0.98357112 0.98342701\n 0.98904741 0.99409137 0.98241822 0.9966854  0.99625306 0.99755008\n 0.99812653 0.99798242 0.99308258 0.99192967 0.99798242 0.9844358\n 0.99077677 0.99063266 0.99452371 0.99365903 0.99567661 0.98976798]\nrecall for all classes in train phase [0.6119403  0.90692641 0.80578512 0.85849057 0.53333333 0.94183673\n 0.65909091 0.90714286 0.43902439 0.92829457 0.77777778 0.875\n 0.921875   0.69879518 0.86868687 0.23076923 0.43333333 0.90277778\n 0.96987952 0.68       0.85454545 0.51428571 0.45       0.92952381\n 0.67045455 0.47222222 0.51923077 0.8630137  0.83146067 0.78443114]\nprecision for all classes in train phase [0.69491525 0.92494481 0.84782609 0.89215686 0.55172414 0.90136719\n 0.73417722 0.94074074 0.72       0.87408759 0.77165354 0.85681293\n 0.92913386 0.78378378 0.88295688 0.66666667 0.59090909 0.86666667\n 0.95266272 0.73913043 0.85454545 0.62068966 0.75       0.87298748\n 0.62765957 0.55737705 0.675      0.84       0.83146067 0.78915663]\nTrain Loss: 0.4858 Acc: 0.8605\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99028571 0.98514286 0.96857143 0.99028571 0.992      0.97142857\n 0.98742857 0.992      0.99542857 0.94514286 0.96571429 0.98628571\n 0.98228571 0.98742857 0.97257143 0.996      0.99714286 0.99542857\n 0.996      0.99828571 0.992      0.99257143 0.99828571 0.97028571\n 0.98285714 0.98628571 0.99485714 0.99428571 0.99428571 0.99142857]\nrecall for all classes in validation phase [0.41176471 0.85344828 0.75206612 0.40740741 0.4375     0.89430894\n 0.59090909 0.72222222 0.27272727 0.87209302 0.8125     0.8411215\n 0.875      0.71428571 0.86290323 0.28571429 0.75       0.55555556\n 0.85714286 0.85714286 0.76190476 0.44444444 0.4        0.84090909\n 0.40909091 0.42105263 0.57142857 0.89189189 0.69565217 0.66666667]\nprecision for all classes in validation phase [0.5        0.91666667 0.78448276 0.91666667 0.58333333 0.90163934\n 0.5        0.86666667 1.         0.78125    0.52       0.92783505\n 0.88188976 0.48387097 0.77536232 0.5        0.66666667 1.\n 0.97297297 0.75       0.88888889 0.72727273 1.         0.78169014\n 0.34615385 0.38095238 0.72727273 0.84615385 0.84210526 0.96551724]\nVal Loss: 0.8879 Acc: 0.7960\nEpoch 7/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:08<00:00, 10.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99466782 0.99236201 0.9822741  0.99639718 0.99437959 0.98140942\n 0.9922179  0.99697363 0.99625306 0.97521257 0.9877504  0.99120911\n 0.98933564 0.99495605 0.98702983 0.99740597 0.99740597 0.9988471\n 0.99855887 0.99855887 0.99524427 0.99625306 0.99841476 0.98385935\n 0.99394725 0.99178556 0.99639718 0.99682951 0.99798242 0.99048854]\nrecall for all classes in train phase [0.71641791 0.94155844 0.86363636 0.87735849 0.7        0.95102041\n 0.63636364 0.9        0.58536585 0.93217054 0.82936508 0.91981132\n 0.93945312 0.78313253 0.9030303  0.65384615 0.56666667 0.97222222\n 0.96385542 0.76       0.8969697  0.68571429 0.65       0.90857143\n 0.72727273 0.56944444 0.69230769 0.93150685 0.91011236 0.81437126]\nprecision for all classes in train phase [0.72727273 0.94360087 0.88       0.88571429 0.66666667 0.92003949\n 0.71794872 0.94736842 0.72727273 0.90413534 0.83266932 0.9352518\n 0.91793893 0.79268293 0.91411043 0.65384615 0.77272727 0.92105263\n 0.97560976 0.82608696 0.90243902 0.92307692 0.76470588 0.88170055\n 0.7804878  0.6119403  0.8        0.91891892 0.93103448 0.79532164]\nTrain Loss: 0.3852 Acc: 0.8922\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 31.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99542857 0.98857143 0.96857143 0.99314286 0.99485714 0.96628571\n 0.99085714 0.99714286 0.99428571 0.96228571 0.97371429 0.98742857\n 0.98914286 0.99371429 0.98228571 0.99714286 0.99714286 0.99828571\n 0.99485714 0.99714286 0.99314286 0.99371429 0.99828571 0.97257143\n 0.98971429 0.99028571 0.99542857 0.99142857 0.99485714 0.98571429]\nrecall for all classes in validation phase [0.64705882 0.86206897 0.78512397 0.77777778 0.5625     0.89430894\n 0.68181818 0.86111111 0.45454545 0.87984496 0.828125   0.89719626\n 0.9296875  0.76190476 0.86290323 0.28571429 0.375      0.83333333\n 0.92857143 0.85714286 0.92857143 0.66666667 0.8        0.87121212\n 0.45454545 0.42105263 0.64285714 0.72972973 0.7826087  0.64285714]\nprecision for all classes in validation phase [0.84615385 0.96153846 0.76612903 0.77777778 0.81818182 0.86956522\n 0.625      1.         0.55555556 0.86641221 0.60227273 0.89719626\n 0.92248062 0.72727273 0.88429752 1.         1.         1.\n 0.86666667 0.6        0.8125     0.70588235 0.66666667 0.78767123\n 0.625      0.57142857 0.75       0.84375    0.81818182 0.72972973]\nVal Loss: 0.7567 Acc: 0.8337\nEpoch 8/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:08<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99582072 0.99293846 0.98501225 0.99769419 0.99654129 0.98342701\n 0.99567661 0.99827064 0.9966854  0.98212999 0.98962387 0.9900562\n 0.99135322 0.9955325  0.98933564 0.99755008 0.99798242 0.99870298\n 0.99827064 0.99870298 0.99524427 0.99582072 0.99827064 0.9889033\n 0.99452371 0.99394725 0.99697363 0.99697363 0.99812653 0.99524427]\nrecall for all classes in train phase [0.8358209  0.93506494 0.87809917 0.91509434 0.81666667 0.95204082\n 0.80681818 0.96428571 0.63414634 0.95348837 0.84126984 0.91273585\n 0.94921875 0.77108434 0.92121212 0.53846154 0.66666667 0.94444444\n 0.97590361 0.8        0.88484848 0.72857143 0.75       0.94285714\n 0.81818182 0.66666667 0.73076923 0.93150685 0.94382022 0.90419162]\nprecision for all classes in train phase [0.75675676 0.9578714  0.90425532 0.93269231 0.79032258 0.93206793\n 0.8452381  0.95070423 0.76470588 0.92830189 0.86885246 0.92362768\n 0.93461538 0.84210526 0.9287169  0.73684211 0.83333333 0.93150685\n 0.95294118 0.83333333 0.9125     0.83606557 0.68181818 0.91328413\n 0.76595745 0.72727273 0.84444444 0.92517007 0.91304348 0.89880952]\nTrain Loss: 0.3006 Acc: 0.9127\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.99371429 0.98685714 0.97085714 0.99142857 0.99485714 0.972\n 0.99257143 0.996      0.996      0.96514286 0.98514286 0.98342857\n 0.98857143 0.99485714 0.98114286 0.99828571 0.996      0.99714286\n 0.996      0.99771429 0.99085714 0.99085714 0.99942857 0.97771429\n 0.988      0.98628571 0.98571429 0.99371429 0.99371429 0.98228571]\nrecall for all classes in validation phase [0.70588235 0.80172414 0.82644628 0.81481481 0.6875     0.92276423\n 0.77272727 0.88888889 0.45454545 0.86821705 0.765625   0.77570093\n 0.8828125  0.76190476 0.92741935 0.85714286 0.5        0.77777778\n 0.88095238 0.85714286 0.78571429 0.61111111 0.8        0.82575758\n 0.40909091 0.73684211 0.64285714 0.81081081 0.73913043 0.85714286]\nprecision for all classes in validation phase [0.66666667 1.         0.76923077 0.6875     0.73333333 0.88326848\n 0.68       0.91428571 0.83333333 0.89243028 0.81666667 0.94318182\n 0.95762712 0.8        0.82733813 0.75       0.57142857 0.93333333\n 0.94871795 0.66666667 0.825      0.55       1.         0.872\n 0.52941176 0.42424242 0.31034483 0.88235294 0.77272727 0.59016393]\nVal Loss: 0.8357 Acc: 0.8331\nEpoch 9/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:08<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99726185 0.99567661 0.9889033  0.99769419 0.99769419 0.98904741\n 0.99755008 0.99726185 0.99726185 0.98184176 0.99207379 0.99409137\n 0.99409137 0.99769419 0.99250612 0.99827064 0.99841476 0.99927944\n 0.99855887 0.99942355 0.99625306 0.99582072 0.99899121 0.9922179\n 0.99697363 0.99639718 0.99755008 0.99697363 0.99711774 0.99510016]\nrecall for all classes in train phase [0.86567164 0.96103896 0.91735537 0.91509434 0.85       0.96734694\n 0.88636364 0.90714286 0.68292683 0.95348837 0.9047619  0.94103774\n 0.95507812 0.90361446 0.94747475 0.73076923 0.8        0.98611111\n 0.96987952 0.88       0.92121212 0.71428571 0.7        0.95809524\n 0.85227273 0.80555556 0.86538462 0.94520548 0.91011236 0.89221557]\nprecision for all classes in train phase [0.85294118 0.97368421 0.92307692 0.93269231 0.87931034 0.95564516\n 0.91764706 0.95488722 0.82352941 0.92655367 0.88030888 0.96144578\n 0.96449704 0.90361446 0.94747475 0.79166667 0.82758621 0.94666667\n 0.96987952 0.95652174 0.92121212 0.84745763 0.93333333 0.94018692\n 0.90361446 0.84057971 0.81818182 0.91390728 0.87096774 0.9030303 ]\nTrain Loss: 0.2427 Acc: 0.9340\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 31.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.98685714 0.98171429 0.97257143 0.992      0.99314286 0.96914286\n 0.98171429 0.99085714 0.99371429 0.96       0.98342857 0.98857143\n 0.98514286 0.98742857 0.98057143 0.99942857 0.996      0.99771429\n 0.996      0.99828571 0.99028571 0.99257143 0.99771429 0.97771429\n 0.98685714 0.99257143 0.99485714 0.99542857 0.99657143 0.988     ]\nrecall for all classes in validation phase [0.70588235 0.93103448 0.71900826 0.62962963 0.625      0.92276423\n 0.72727273 0.94444444 0.45454545 0.89922481 0.734375   0.94392523\n 0.8515625  0.80952381 0.74193548 0.85714286 0.125      0.88888889\n 0.88095238 0.71428571 0.76190476 0.61111111 0.8        0.81818182\n 0.36363636 0.68421053 0.35714286 0.86486486 0.73913043 0.76190476]\nprecision for all classes in validation phase [0.4        0.81818182 0.86138614 0.80952381 0.625      0.86641221\n 0.38095238 0.70833333 0.5        0.84057971 0.79661017 0.87826087\n 0.93965517 0.48571429 0.9787234  1.         1.         0.88888889\n 0.94871795 0.83333333 0.82051282 0.64705882 0.57142857 0.87804878\n 0.47058824 0.65       1.         0.91428571 1.         0.74418605]\nVal Loss: 0.7692 Acc: 0.8234\nEpoch 10/10\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1388/1388 [02:08<00:00, 10.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in train phase [0.99726185 0.99437959 0.98587693 0.99812653 0.99726185 0.98702983\n 0.99682951 0.99769419 0.99855887 0.98342701 0.99034443 0.99149733\n 0.99394725 0.99726185 0.9900562  0.99855887 0.99783831 0.99913532\n 0.99812653 0.99927944 0.99538838 0.99524427 0.99942355 0.99048854\n 0.99538838 0.99755008 0.99740597 0.99841476 0.99783831 0.99481193]\nrecall for all classes in train phase [0.86567164 0.95238095 0.89049587 0.9245283  0.86666667 0.95816327\n 0.88636364 0.95       0.87804878 0.95445736 0.86507937 0.93396226\n 0.95703125 0.86746988 0.92727273 0.76923077 0.7        0.94444444\n 0.96987952 0.92       0.89090909 0.68571429 0.9        0.94285714\n 0.84090909 0.86111111 0.80769231 0.95890411 0.8988764  0.89820359]\nprecision for all classes in train phase [0.85294118 0.96280088 0.90546218 0.95145631 0.82539683 0.95040486\n 0.86666667 0.93661972 0.87804878 0.9354226  0.8685259  0.92740047\n 0.96078431 0.9        0.93292683 0.83333333 0.77777778 0.97142857\n 0.95266272 0.88461538 0.91304348 0.81355932 0.9        0.93220339\n 0.80434783 0.89855072 0.84       0.96551724 0.93023256 0.88757396]\nTrain Loss: 0.2692 Acc: 0.9272\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 350/350 [00:11<00:00, 30.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy for all classes in validation phase [0.98571429 0.98685714 0.976      0.99314286 0.99371429 0.96228571\n 0.99257143 0.98914286 0.99314286 0.96171429 0.97657143 0.98571429\n 0.98171429 0.99314286 0.96742857 0.99942857 0.996      0.992\n 0.99714286 0.99714286 0.99142857 0.992      0.996      0.97257143\n 0.988      0.99085714 0.99657143 0.99542857 0.99428571 0.99314286]\nrecall for all classes in validation phase [0.64705882 0.85344828 0.72727273 0.77777778 0.75       0.95934959\n 0.63636364 0.47222222 0.         0.89534884 0.78125    0.8317757\n 0.78125    0.52380952 0.88709677 0.85714286 0.125      0.94444444\n 0.88095238 0.85714286 0.76190476 0.38888889 1.         0.86363636\n 0.40909091 0.57894737 0.71428571 0.86486486 0.7826087  0.78571429]\nprecision for all classes in validation phase [0.36666667 0.94285714 0.90721649 0.77777778 0.63157895 0.80821918\n 0.73684211 1.         0.         0.85239852 0.64935065 0.92708333\n 0.96153846 0.84615385 0.71895425 1.         1.         0.56666667\n 1.         0.6        0.86486486 0.7        0.41666667 0.79166667\n 0.52941176 0.57894737 0.83333333 0.91428571 0.7826087  0.91666667]\nVal Loss: 0.8355 Acc: 0.8154\n","output_type":"stream"}]}]}